{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse WoS .txt, and save to .json\n",
    "- parse wos .txt\n",
    "- parse in batches\n",
    "- dump to .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse WoS .txt files to dicts\n",
    "def parse_wos_txt(file_path):\n",
    "    # Read WoS .txt file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Split the content into individual records\n",
    "    records = content.strip().split(\"\\nER\\n\")\n",
    "    records = [record.strip() + \"\\nER\" for record in records if record.strip()]\n",
    "\n",
    "    # Extract the fields\n",
    "    papers = []\n",
    "    for record in tqdm(records, desc='Progress: '):\n",
    "        paper = {}\n",
    "        lines = record.split('\\n')\n",
    "        for line in lines:\n",
    "            if line.startswith('PT '):\n",
    "                paper['PT'] = line[3:]\n",
    "\n",
    "            elif line.startswith('AU '):\n",
    "                aus = []\n",
    "                aus.append(line[3:])\n",
    "                # Read all subsequent AU lines until the next field starts\n",
    "                for next_line in lines[lines.index(line) + 1:]:\n",
    "                    if next_line.startswith((' ', '\\t')):\n",
    "                        aus.append(next_line.strip())\n",
    "                    else:\n",
    "                        break\n",
    "                paper['AU'] = '; '.join(aus)  \n",
    "\n",
    "            elif line.startswith('AF '):\n",
    "                afs = []\n",
    "                afs.append(line[3:])\n",
    "                # Read all subsequent AF lines until the next field starts\n",
    "                for next_line in lines[lines.index(line) + 1:]:\n",
    "                    if next_line.startswith((' ', '\\t')):\n",
    "                        afs.append(next_line.strip())\n",
    "                    else:\n",
    "                        break\n",
    "                paper['AF'] = '; '.join(afs)     \n",
    "\n",
    "            elif line.startswith('TI '):\n",
    "                tis = []\n",
    "                tis.append(line[3:])\n",
    "                # Read all subsequent AF lines until the next field starts\n",
    "                for next_line in lines[lines.index(line) + 1:]:\n",
    "                    if next_line.startswith((' ', '\\t')):\n",
    "                        tis.append(next_line.strip())\n",
    "                    else:\n",
    "                        break\n",
    "                paper['TI'] = ' '.join(tis)    \n",
    "\n",
    "            elif line.startswith('SO '):\n",
    "                sos = []\n",
    "                sos.append(line[3:])\n",
    "                # Read all subsequent AF lines until the next field starts\n",
    "                for next_line in lines[lines.index(line) + 1:]:\n",
    "                    if next_line.startswith((' ', '\\t')):\n",
    "                        sos.append(next_line.strip())\n",
    "                    else:\n",
    "                        break\n",
    "                paper['SO'] = ' '.join(sos)  \n",
    "\n",
    "            elif line.startswith('LA '):\n",
    "                paper['LA'] = line[3:]   \n",
    "\n",
    "            elif line.startswith('DT '):\n",
    "                paper['DT'] = line[3:]     \n",
    "\n",
    "            elif line.startswith('DE '):\n",
    "                des = []\n",
    "                des.append(line[3:])\n",
    "                # Read all subsequent AF lines until the next field starts\n",
    "                for next_line in lines[lines.index(line) + 1:]:\n",
    "                    if next_line.startswith((' ', '\\t')):\n",
    "                        des.append(next_line.strip())\n",
    "                    else:\n",
    "                        break\n",
    "                paper['DE'] = ' '.join(des) \n",
    "\n",
    "            elif line.startswith('ID '):\n",
    "                ids = []\n",
    "                ids.append(line[3:])\n",
    "                # Read all subsequent AF lines until the next field starts\n",
    "                for next_line in lines[lines.index(line) + 1:]:\n",
    "                    if next_line.startswith((' ', '\\t')):\n",
    "                        ids.append(next_line.strip())\n",
    "                    else:\n",
    "                        break\n",
    "                paper['ID'] = ' '.join(ids)\n",
    "\n",
    "            elif line.startswith('AB '):\n",
    "                abs = []\n",
    "                abs.append(line[3:])\n",
    "                # Read all subsequent AF lines until the next field starts\n",
    "                for next_line in lines[lines.index(line) + 1:]:\n",
    "                    if next_line.startswith((' ', '\\t')):\n",
    "                        abs.append(next_line.strip())\n",
    "                    else:\n",
    "                        break\n",
    "                paper['AB'] = ' '.join(abs)                                                \n",
    "\n",
    "            elif line.startswith('C1 '):\n",
    "                c1s = []\n",
    "                c1s.append(line[3:])\n",
    "                # Read all subsequent AF lines until the next field starts\n",
    "                for next_line in lines[lines.index(line) + 1:]:\n",
    "                    if next_line.startswith((' ', '\\t')):\n",
    "                        c1s.append(next_line.strip())\n",
    "                    else:\n",
    "                        break\n",
    "                paper['C1'] = ';'.join(c1s)    \n",
    "\n",
    "            elif line.startswith('C3 '):\n",
    "                c3s = []\n",
    "                c3s.append(line[3:])\n",
    "                # Read all subsequent AF lines until the next field starts\n",
    "                for next_line in lines[lines.index(line) + 1:]:\n",
    "                    if next_line.startswith((' ', '\\t')):\n",
    "                        c3s.append(next_line.strip())\n",
    "                    else:\n",
    "                        break\n",
    "                paper['C3'] = ' '.join(c3s)        \n",
    "\n",
    "            elif line.startswith('RP '):\n",
    "                rps = []\n",
    "                rps.append(line[3:])\n",
    "                # Read all subsequent AF lines until the next field starts\n",
    "                for next_line in lines[lines.index(line) + 1:]:\n",
    "                    if next_line.startswith((' ', '\\t')):\n",
    "                        rps.append(next_line.strip())\n",
    "                    else:\n",
    "                        break\n",
    "                paper['RP'] = ' '.join(rps)       \n",
    "\n",
    "            elif line.startswith('EM '):\n",
    "                ems = []\n",
    "                ems.append(line[3:])\n",
    "                # Read all subsequent AF lines until the next field starts\n",
    "                for next_line in lines[lines.index(line) + 1:]:\n",
    "                    if next_line.startswith((' ', '\\t')):\n",
    "                        ems.append(next_line.strip())\n",
    "                    else:\n",
    "                        break\n",
    "                paper['EM'] = ' '.join(ems)    \n",
    "\n",
    "            elif line.startswith('FU '):\n",
    "                fus = []\n",
    "                fus.append(line[3:])\n",
    "                # Read all subsequent AF lines until the next field starts\n",
    "                for next_line in lines[lines.index(line) + 1:]:\n",
    "                    if next_line.startswith((' ', '\\t')):\n",
    "                        fus.append(next_line.strip())\n",
    "                    else:\n",
    "                        break\n",
    "                paper['FU'] = ' '.join(fus)        \n",
    "\n",
    "            elif line.startswith('FX '):\n",
    "                fxs = []\n",
    "                fxs.append(line[3:])\n",
    "                # Read all subsequent AF lines until the next field starts\n",
    "                for next_line in lines[lines.index(line) + 1:]:\n",
    "                    if next_line.startswith((' ', '\\t')):\n",
    "                        fxs.append(next_line.strip())\n",
    "                    else:\n",
    "                        break\n",
    "                paper['FX'] = ' '.join(fxs)         \n",
    "\n",
    "            elif line.startswith('CR '):\n",
    "                crs = []\n",
    "                crs.append(line[3:])\n",
    "                # Read all subsequent AF lines until the next field starts\n",
    "                for next_line in lines[lines.index(line) + 1:]:\n",
    "                    if next_line.startswith((' ', '\\t')):\n",
    "                        crs.append(next_line.strip())\n",
    "                    else:\n",
    "                        break\n",
    "                paper['CR'] = ';'.join(crs)   \n",
    "\n",
    "            elif line.startswith('NR '):\n",
    "                paper['NR'] = line[3:]\n",
    "\n",
    "            elif line.startswith('TC '):\n",
    "                paper['TC'] = line[3:]\n",
    "\n",
    "            elif line.startswith('Z9 '):\n",
    "                paper['Z9'] = line[3:]   \n",
    "\n",
    "            elif line.startswith('U1 '):\n",
    "                paper['U1'] = line[3:]\n",
    "\n",
    "            elif line.startswith('U2 '):\n",
    "                paper['U2'] = line[3:]   \n",
    "\n",
    "            elif line.startswith('PU '):\n",
    "                paper['PU'] = line[3:]\n",
    "\n",
    "            elif line.startswith('PI '):\n",
    "                paper['PI'] = line[3:]              \n",
    "\n",
    "            elif line.startswith('PA '):\n",
    "                paper['PA'] = line[3:] \n",
    "\n",
    "            elif line.startswith('SN '):\n",
    "                paper['SN'] = line[3:]    \n",
    "\n",
    "            elif line.startswith('EI '):\n",
    "                paper['EI'] = line[3:]        \n",
    "\n",
    "            elif line.startswith('J9 '):\n",
    "                paper['J9'] = line[3:]      \n",
    "\n",
    "            elif line.startswith('JI '):\n",
    "                paper['JI'] = line[3:]      \n",
    "\n",
    "            elif line.startswith('PD '):\n",
    "                paper['PD'] = line[3:]      \n",
    "\n",
    "            elif line.startswith('PY '):\n",
    "                paper['PY'] = line[3:]   \n",
    "\n",
    "            elif line.startswith('VL '):\n",
    "                paper['VL'] = line[3:] \n",
    "\n",
    "            elif line.startswith('IS '):\n",
    "                paper['IS'] = line[3:]    \n",
    "\n",
    "            elif line.startswith('BP '):\n",
    "                paper['BP'] = line[3:]   \n",
    "\n",
    "            elif line.startswith('EP '):\n",
    "                paper['EP'] = line[3:]   \n",
    "\n",
    "            elif line.startswith('AR '):\n",
    "                paper['AR'] = line[3:]  \n",
    "\n",
    "            elif line.startswith('DI '):\n",
    "                paper['DI'] = line[3:]  \n",
    "\n",
    "            elif line.startswith('EA '):\n",
    "                paper['EA'] = line[3:] \n",
    "\n",
    "            elif line.startswith('PG '):\n",
    "                paper['PG'] = line[3:] \n",
    "\n",
    "            elif line.startswith('WC '):\n",
    "                wcs = []\n",
    "                wcs.append(line[3:])\n",
    "                # Read all subsequent AF lines until the next field starts\n",
    "                for next_line in lines[lines.index(line) + 1:]:\n",
    "                    if next_line.startswith((' ', '\\t')):\n",
    "                        wcs.append(next_line.strip())\n",
    "                    else:\n",
    "                        break\n",
    "                paper['WC'] = ' '.join(wcs)  \n",
    "\n",
    "            elif line.startswith('WE '):\n",
    "                paper['WE'] = line[3:]          \n",
    "\n",
    "            elif line.startswith('SC '):\n",
    "                paper['SC'] = line[3:]  \n",
    "\n",
    "            elif line.startswith('GA '):\n",
    "                paper['GA'] = line[3:]  \n",
    "\n",
    "            elif line.startswith('UT '):\n",
    "                paper['UT'] = line[3:]  \n",
    "\n",
    "            elif line.startswith('PM '):\n",
    "                paper['PM'] = line[3:]  \n",
    "\n",
    "            elif line.startswith('OA '):\n",
    "                paper['OA'] = line[3:]    \n",
    "\n",
    "            elif line.startswith('DA '):\n",
    "                paper['DA'] = line[3:]  \n",
    "\n",
    "        papers.append(paper)\n",
    "    \n",
    "    return papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing wos .txt files in batches\n",
    "def parse_wos_txt_batches(os_path): \n",
    "    # (os_path is exactly the path to the folder containing all WoS .txt files)\n",
    "    # read the os path\n",
    "    fn_exs = os.listdir(os_path)\n",
    "\n",
    "    # Spliter filename and extension\n",
    "    fns = []\n",
    "    for fn_ex in fn_exs:\n",
    "        fn, ex = os.path.splitext(fn_ex)\n",
    "        if ex == '.txt':\n",
    "            fns.append(fn)\n",
    "\n",
    "    # Get all the papers for each author as dict\n",
    "    papers = []\n",
    "    for fn in fns:\n",
    "        fn_txt_path = f'{os_path}\\{fn}.txt'\n",
    "        papers += parse_wos_txt(fn_txt_path)\n",
    "\n",
    "    return papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 588/588 [00:00<00:00, 1577.20it/s]\n",
      "Progress: 100%|██████████| 432/432 [00:00<00:00, 2215.52it/s]\n",
      "Progress: 100%|██████████| 408/408 [00:00<00:00, 2199.26it/s]\n",
      "Progress: 100%|██████████| 174/174 [00:00<00:00, 2220.23it/s]\n",
      "Progress: 100%|██████████| 259/259 [00:00<00:00, 1686.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# Try the test data\n",
    "os_path = 'original_data\\Citation Laureates_test'\n",
    "papers = parse_wos_txt_batches(os_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1861"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PT': 'J',\n",
       " 'AU': \"O'Connell, RP; Liaw, K; Wellhausen, N; Chuckran, CA; Bhojnagarwala, PS; Bordoloi, D; Park, D; Shupin, N; Kulp, D; June, CH; Weiner, D\",\n",
       " 'AF': \"O'Connell, Ryan P.; Liaw, Kevin; Wellhausen, Nils; Chuckran, Christopher A.; Bhojnagarwala, Pratik S.; Bordoloi, Devivasha; Park, Daniel; Shupin, Nicholas; Kulp, Daniel; June, Carl H.; Weiner, David\",\n",
       " 'TI': 'Format-tuning of in vivo-launched bispecific T cell engager enhances efficacy against renal cell carcinoma',\n",
       " 'SO': 'JOURNAL FOR IMMUNOTHERAPY OF CANCER',\n",
       " 'LA': 'English',\n",
       " 'DT': 'Article',\n",
       " 'DE': 'Renal Cell Carcinoma; Antibody; Bispecific T cell engager - BiTE; Kidney Cancer',\n",
       " 'ID': 'CARBONIC-ANHYDRASE-IX; ANTIBODY; EXPRESSION; DELIVERY',\n",
       " 'AB': \"Background Advanced clear cell renal cell carcinoma (ccRCC) is a prevalent kidney cancer for which long-term survival rates are abysmal, though immunotherapies are showing potential. Not yet clinically vetted are bispecific T cell engagers (BTEs) that activate T cell-mediated cancer killing through intercellular synapsing. Multiple BTE formats exist, however, with limited cross-characterizations to help optimize new drug design. Here, we developed BTEs to treat ccRCC by targeting carbonic anhydrase 9 (CA9) while characterizing the persistent BTE (PBTE) format and comparing it to a new format, the persistent multivalent T cell engager (PMTE). These antibody therapies against ccRCC are developed as both recombinant and synthetic DNA (synDNA) medicines.Methods Antibody formatting effects on binding kinetics were assessed by flow cytometry and intercellular synaptic strength assays while potency was tested using T-cell activation and cytotoxicity assays. Mouse models were used to study antibody plasma and tumor pharmacokinetics, as well as antitumor efficacy as both recombinant and synDNA medicines. Specifically, three models using ccRCC cell line xenografts and human donor T cells in immunodeficient mice were used to support this study.Results Compared with a first-generation BTE, we show that the PBTE reduced avidity, intercellular synaptic strength, cytotoxic potency by as much as 33-fold, and ultimately efficacy against ccRCC tumors in vivo. However, compared with the PBTE, we demonstrate that the PMTE improved cell avidity, restored intercellular synapses, augmented cytotoxic potency by 40-fold, improved tumor distribution pharmacokinetics by 2-fold, and recovered synDNA efficacy in mouse tumor models by 20-fold. All the while, the PMTE displayed a desirable half-life of 4 days in mice compared with the conventional BTE's 2 hours.Conclusions With impressive efficacy, the CA9-targeted PMTE is a promising new therapy for advanced ccRCC, which can be effectively delivered through synDNA. The highly potent PMTE format itself is a promising new tool for future applications in the multispecific antibody space.\",\n",
       " 'C1': \"[O'Connell, Ryan P.; Park, Daniel] Univ Penn, Perelman Sch Med, Philadelphia, PA USA.;[O'Connell, Ryan P.; Liaw, Kevin; Bhojnagarwala, Pratik S.; Bordoloi, Devivasha; Park, Daniel; Shupin, Nicholas; Kulp, Daniel; Weiner, David] Wistar Inst Anat & Biol, Vaccine & Immunotherapy Ctr, Philadelphia, PA 19104 USA.;[Wellhausen, Nils; June, Carl H.] Univ Penn, Perelman Sch Med, Ctr Cellular Immunotherapies, Philadelphia, PA USA.;[Chuckran, Christopher A.] LUMICKS, Waltham, MA USA.;[June, Carl H.] Univ Penn, Perelman Sch Med, Parker Inst Canc Immunotherapy, Philadelphia, PA USA.\",\n",
       " 'C3': 'University of Pennsylvania; The Wistar Institute; University of Pennsylvania; University of Pennsylvania',\n",
       " 'RP': 'Weiner, D (corresponding author), Wistar Inst Anat & Biol, Vaccine & Immunotherapy Ctr, Philadelphia, PA 19104 USA.',\n",
       " 'EM': 'dweiner@wistar.org',\n",
       " 'FU': 'WW Smith Charitable Trust; University of Pennsylvania Cell Center',\n",
       " 'FX': \"We would like to thank The Wistar Institute's Animal Facility for providing care to the animals and Flow Cytometry Core for providingflow cytometers. We would also like to thank the University of Pennsylvania Cell Center for providing donor immune cells and MSK for providing the SKRC-52 cell line.\",\n",
       " 'CR': \"Adams GP, 2006, CLIN CANCER RES, V12, P1599, DOI 10.1158/1078-0432.CCR-05-2217;[Anonymous], 2022, Cancer STAT facts: kidney and renal pelvis cancer;Arnett KL, 2004, P NATL ACAD SCI USA, V101, P16268, DOI 10.1073/pnas.0407359101;Bacac M, 2016, CLIN CANCER RES, V22, P3286, DOI 10.1158/1078-0432.CCR-15-1696;Bhojnagarwala PS, 2022, MOL THER-ONCOLYTICS, V26, P289, DOI 10.1016/j.omto.2022.07.003;Bluemel C, 2010, CANCER IMMUNOL IMMUN, V59, P1197, DOI 10.1007/s00262-010-0844-y;Bordoloi D, 2022, JCI INSIGHT, V7, DOI 10.1172/jci.insight.162553;Brunton L., 2017, Goodman and Gilman's the pharmacological basis of therapeutics, V13th;Bui MHT, 2003, CLIN CANCER RES, V9, P802;Chamie K, 2017, JAMA ONCOL, V3, P913, DOI 10.1001/jamaoncol.2016.4419;Einsele H, 2020, CANCER-AM CANCER SOC, V126, P3192, DOI 10.1002/cncr.32909;Ellerman D, 2019, METHODS, V154, P102, DOI 10.1016/j.ymeth.2018.10.026;Genega EM, 2010, AM J CLIN PATHOL, V134, P873, DOI 10.1309/AJCPPPR57HNJMSLZ;Grinceviciene S., 2019, Clinical trials involving carbonic anhydrase IX as a target for cancer diagnosis and treatment, P335;Haber L, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-93842-0;Halim L, 2022, FRONT IMMUNOL, V13, DOI 10.3389/fimmu.2022.836549;Heldin CH, 2004, NAT REV CANCER, V4, P806, DOI 10.1038/nrc1456;Hernandez-Hoyos G, 2016, MOL CANCER THER, V15, P2155, DOI 10.1158/1535-7163.MCT-15-0242;Hezareh M, 2001, J VIROL, V75, P12161, DOI 10.1128/JVI.75.24.12161-12168.2001;Hsieh JJ, 2017, NAT REV DIS PRIMERS, V3, DOI 10.1038/nrdp.2017.9;Jensen HK, 2008, BJU INT, V101, P41, DOI 10.1111/j.1464-410X.2008.07649.x;Lamers C.H., 2006, J CLIN ONCOL, V24, pe20, DOI [10.1200/JCO.2006.05.9964, DOI 10.1200/JCO.2006.05.9964, 10.1200/jco.2006.05.9964];Lamers CHJ, 2013, MOL THER, V21, P904, DOI 10.1038/mt.2013.17;Larson RC, 2022, NATURE, V604, P563, DOI 10.1038/s41586-022-04585-5;Lee E, 2023, J IMMUNOTHER CANCER, V11, DOI 10.1136/jitc-2023-007494;Li J, 2017, CANCER CELL, V31, P383, DOI 10.1016/j.ccell.2017.02.001;Lorenczewski G, 2017, BLOOD, V130;LUND J, 1991, J IMMUNOL, V147, P2657;Mandikian D, 2018, MOL CANCER THER, V17, P776, DOI 10.1158/1535-7163.MCT-17-0657;Mboge MY, 2018, METABOLITES, V8, DOI 10.3390/metabo8010019;National Cancer Institute, Renal cell cancer treatment physican data query;Nie Siwei, 2020, Antib Ther, V3, P18, DOI 10.1093/abt/tbaa003;Park DH, 2023, MOL THER-ONCOLYTICS, V28, P249, DOI 10.1016/j.omto.2023.02.004;Pastorekova S, 2019, CANCER METAST REV, V38, P65, DOI 10.1007/s10555-019-09799-0;Patel A, 2020, BIODRUGS, V34, P273, DOI 10.1007/s40259-020-00412-3;Perales-Puchalt A, 2019, JCI INSIGHT, V4, DOI 10.1172/jci.insight.126086;Proetzel G, 2014, METHODS, V65, P148, DOI 10.1016/j.ymeth.2013.07.005;Rudnik-Jansen I, 2021, J CONTROL RELEASE, V337, P248, DOI 10.1016/j.jconrel.2021.07.007;Sardesai NY, 2011, CURR OPIN IMMUNOL, V23, P421, DOI 10.1016/j.coi.2011.03.008;Tatari N, 2022, FRONT IMMUNOL, V13, DOI 10.3389/fimmu.2022.905768;Thurber GM, 2008, ADV DRUG DELIVER REV, V60, P1421, DOI 10.1016/j.addr.2008.04.012;Vafa O, 2020, FRONT ONCOL, V10, DOI 10.3389/fonc.2020.00446;Wei J, 2022, FRONT IMMUNOL, V13, DOI 10.3389/fimmu.2022.1035276;Wellhausen N, 2023, SCI TRANSL MED, V15, DOI 10.1126/scitranslmed.adi1145;Xu C, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0009625;Yadav R, 2022, PHARMACEUTICS, V14, DOI 10.3390/pharmaceutics14050970\",\n",
       " 'NR': '46',\n",
       " 'TC': '0',\n",
       " 'Z9': '0',\n",
       " 'U1': '2',\n",
       " 'U2': '2',\n",
       " 'PU': 'BMJ PUBLISHING GROUP',\n",
       " 'PI': 'LONDON',\n",
       " 'PA': 'BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND',\n",
       " 'EI': '2051-1426',\n",
       " 'J9': 'J IMMUNOTHER CANCER',\n",
       " 'JI': 'J. Immunother. Cancer',\n",
       " 'PD': 'JUN',\n",
       " 'PY': '2024',\n",
       " 'VL': '12',\n",
       " 'IS': '6',\n",
       " 'AR': 'e008733',\n",
       " 'DI': '10.1136/jitc-2023-008733',\n",
       " 'PG': '17',\n",
       " 'WC': 'Oncology; Immunology',\n",
       " 'WE': 'Science Citation Index Expanded (SCI-EXPANDED)',\n",
       " 'SC': 'Oncology; Immunology',\n",
       " 'GA': 'TB5X1',\n",
       " 'UT': 'WOS:001238821600001',\n",
       " 'PM': '38834201',\n",
       " 'OA': 'gold',\n",
       " 'DA': '2024-07-10'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dict to json\n",
    "with open('wos_data.json', 'w') as f:\n",
    "    json.dump(papers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dict from json\n",
    "with open('wos_data.json', 'r') as f:\n",
    "    wos_data = json.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
